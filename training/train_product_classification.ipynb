{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ca93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import texthero as hero\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_path = os.environ['DATASET_PATH']\n",
    "model_path = os.environ['MODEL_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8f2782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clean_dataset():\n",
    "    \"\"\"This function open and clean the dataset from csv file\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        df_x : DataFrame\n",
    "            Data frame with the features for training\n",
    "            \n",
    "        df_y : DataFrame\n",
    "            Data frame with the labels for training\n",
    "    \"\"\"\n",
    "    \n",
    "    data_frame = pd.read_csv(dataset_path)\n",
    "    data_frame = data_frame.drop(columns=['product_id', 'seller_id', 'search_page', 'position', 'order_counts',\n",
    "                                          'express_delivery', 'minimum_quantity', 'view_counts', 'creation_date'])\n",
    "    \n",
    "    data_frame = data_frame.dropna()\n",
    "    \n",
    "    df_y = data_frame['category']\n",
    "    df_x = data_frame.drop(columns=['category'])\n",
    "    \n",
    "    return df_x, df_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99ee58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(model_estimator, X_train, y_train):\n",
    "    \"\"\"This function make and execute the random search to train RandomForest classifier\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        model_estimator : Pipeline\n",
    "            The pipeline for train the model with text features\n",
    "            \n",
    "        X_train : DataFrame\n",
    "            Data frame with the features for training\n",
    "            \n",
    "        y_train : DataFrame\n",
    "            Data frame with the labels for training\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        RandomizedSearchCV :\n",
    "            The model trained with the best configuration\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    \n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]# Create the random grid\n",
    "    random_grid = {'clf__n_estimators': n_estimators,\n",
    "                   'clf__max_depth': max_depth,\n",
    "                   'clf__min_samples_split': min_samples_split,\n",
    "                   'clf__min_samples_leaf': min_samples_leaf,\n",
    "                   'clf__bootstrap': bootstrap}\n",
    "    \n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    rf_RandomGrid = RandomizedSearchCV(estimator = model_estimator, n_iter=1, scoring='f1_macro', \n",
    "                                       param_distributions = random_grid, cv = cv, verbose=2, n_jobs=-1)\n",
    "    rf_RandomGrid.fit(X_train, y_train)\n",
    "    \n",
    "    return rf_RandomGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6798c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_val(model_estimator, X_train, y_train):\n",
    "    \"\"\"This function execute the model training and evaluate the fit model with cross validation score\n",
    "       Parameters\n",
    "        ----------\n",
    "        model_estimator : Pipeline\n",
    "            The pipeline for train the model with text features\n",
    "        \n",
    "        X_train : DataFrame\n",
    "            Data frame with the features for training\n",
    "            \n",
    "        y_train : DataFrame\n",
    "            Data frame with the labels for training\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        model :\n",
    "            The model trained with a simple fit\n",
    "        \n",
    "        scores :\n",
    "            The F1 scores results for cross validation \n",
    "    \"\"\"\n",
    "    \n",
    "    model = model_estimator.fit(X_train, y_train)\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    return model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd99ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(pipeline):\n",
    "    \"\"\"This function the pipeline in file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        pipeline : Pipeline\n",
    "            The pipeline for save model in file\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        model :\n",
    "            The file with the model saved\n",
    "            \n",
    "    \"\"\"\n",
    "    with open(model_path, \"wb\") as file:\n",
    "        model = pickle.dump(pipeline, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f64792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(random_search = False):\n",
    "    \"\"\"This function execute the training pipeline for RandomForest classifier with the dataset\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "       random_search : boolean (Default=False)\n",
    "           This value define if the pipeline execute with RandomSearch or only a simple fit cross validation\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    df_x, df_y = read_clean_dataset()\n",
    "    \n",
    "    df_x['query'] = df_x['query'].pipe(hero.clean)\n",
    "    df_x['title'] = df_x['title'].pipe(hero.clean)\n",
    "    df_x['concatenated_tags'] = df_x['concatenated_tags'].pipe(hero.clean)\n",
    "       \n",
    "    # Partition data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_x, \n",
    "                                                        df_y, \n",
    "                                                        test_size=.2, \n",
    "                                                        random_state=12345)   \n",
    "    # Define categorical pipeline\n",
    "    cat_title_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()) \n",
    "    ])\n",
    "    \n",
    "    cat_query_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer())\n",
    "    ])\n",
    "    \n",
    "    cat_tags_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()) \n",
    "    ])\n",
    "\n",
    "    # Define numerical pipeline\n",
    "    num_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "    \n",
    "    #TODO: Using only title as text feature, change comment for use others columns as features\n",
    "    preprocessor = ColumnTransformer(\n",
    "                        transformers=[\n",
    "                            (\"cat_title\", cat_title_pipe, 'title'),\n",
    "                            #(\"num\", num_pipe, make_column_selector(dtype_include=np.number)),\n",
    "                            #(\"cat_query\", cat_query_pipe, 'query'),\n",
    "                            #(\"cat_tags\", cat_tags_pipe, 'concatenated_tags'),\n",
    "                        ]\n",
    "                    )\n",
    "    \n",
    "    # Combine categorical and numerical pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "     \n",
    "    if(random_search):\n",
    "        best_model = random_search(pipe, X_train, y_train)\n",
    "        print (f'Test Accuracy - : {best_model.score(X_test, y_test):.3f}')\n",
    "    else:\n",
    "        best_model, scores = train_cross_val(pipe, X_train, y_train)\n",
    "        print('F1: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "        \n",
    "    save_model(pipe)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f56c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.848 (0.008)\n"
     ]
    }
   ],
   "source": [
    "pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05182e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
